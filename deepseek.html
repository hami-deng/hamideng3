<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DeepSeek 爆火后的新闻报道数据分析</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f9f9f9;
            color: #333;
        }
        h1, h2 {
            color: #2c3e50;
        }
        .section {
            background: #fff;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }
        .section img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin-top: 10px;
        }
        .code {
            background: #f4f4f4;
            padding: 10px;
            border-radius: 4px;
            font-family: "Courier New", Courier, monospace;
            overflow-x: auto;
        }
    </style>
</head>
<body>
    <h1>DeepSeek 爆火后的新闻报道数据分析</h1>

    <!-- DeepSeek 介绍 -->
    <div class="section">
        <h2>1. DeepSeek 介绍</h2>
        <p>
            DeepSeek，全称杭州深度求索人工智能基础技术研究有限公司，是一家创新型科技公司，成立于 2023 年 7 月 17 日。DeepSeek 使用数据蒸馏技术，从海量数据中提取出更为精炼、有用的信息，专注于开发先进的大语言模型（LLM）和相关技术。该公司由知名私募巨头幻方量化孕育而生，凭借其强大的技术背景和创新能力，迅速在人工智能领域崭露头角。
        </p>
        <p>
            2025 年 1 月 27 日，DeepSeek 应用登顶苹果美国地区应用商店免费 APP 下载排行榜，在美区下载榜上超越了 ChatGPT。同日，苹果中国区应用商店免费榜显示，DeepSeek 成为中国区第一。根据公开报道，DeepSeek 的员工规模不及 OpenAI 的 1/5，百人出头的公司中，算子、推理框架、多模态等研发工程师以及深度学习方面的研究人员共有约 70 人，主要在北京分部，其余 30 多人在杭州总部，多为前端、产品以及商务人员。
        </p>
    </div>

    <!-- 数据爬取 -->
    <div class="section">
        <h2>2. 数据爬取</h2>
        <p>
            为了分析 DeepSeek 爆火后的新闻报道数据，我利用 Python 的 Selenium 库编写了一个自动化程序，在火狐浏览器上通过百度搜索爬取相关新闻标题。以下是爬取过程的主要步骤：
        </p>
        <ol>
            <li><strong>环境搭建</strong>：安装必要的 Python 的 Selenium 库和 Firefox 浏览器驱动（GeckoDriver）。</li>
            <li><strong>配置浏览器和初始化</strong>:配置 Firefox 浏览器选项并初始化浏览器,例如无头模式、语言偏好等,自动下载和管理 GeckoDriver。</li>
            <li><strong>新闻标题数据爬取</strong>：在百度搜索页面上输入关键词“DeepSeek 最新消息”，使用 Selenium 定位搜索结果页面的新闻标题元素，提取每条新闻的标题。</li>
            <li><strong>自动翻页和保存</strong>：通过自动程序来点击“下一页”按钮爬取多页数据，将爬取的标题分批写入 CSV 文件。</li>
            <li><strong>日志记录和异常处理</strong>：使用 logging 模块记录程序运行日志，并捕获和处理异常。</li>
        </ol>
        <div class="code">
            <pre>
from selenium import webdriver
from selenium.webdriver import FirefoxOptions
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.firefox import GeckoDriverManager
import csv
import time
import logging
import os

# 设置日志记录
logging.basicConfig(filename='debug.log', level=logging.DEBUG)

def main():
    driver = None  # 提前声明 driver 变量
    try:
        logging.info("正在配置浏览器选项...")
        print("正在配置浏览器选项...")

        # 配置浏览器
        opts = FirefoxOptions()
        # opts.add_argument("--headless")  # 调试时先关闭无头模式
        opts.set_preference("intl.accept_languages", "en-US")

        logging.info("正在初始化浏览器...")
        print("正在初始化浏览器...")

        # 初始化浏览器
        service = webdriver.firefox.service.Service(GeckoDriverManager().install())
        driver = webdriver.Firefox(service=service, options=opts)
        driver.implicitly_wait(10)

        logging.info("正在访问百度搜索页面...")
        print("正在访问百度搜索页面...")

        # 执行搜索
        search_query = "deepseek的最新相关消息"
        driver.get(f"https://www.baidu.com/s?wd={search_query}")

        logging.info("正在等待搜索结果加载...")
        print("正在等待搜索结果加载...")

        # 等待搜索结果加载
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.result.c-container"))
        )

        logging.info("正在解析文章数据...")
        print("正在解析文章数据...")

        # 解析数据
        titles = []
        max_titles = 100  # 目标标题数量
        page_count = 1  # 当前页码
        batch_size = 10  # 每批写入 10 条
        csv_file = "deepseek_news.csv"  # 输出文件名

        # 初始化 CSV 文件（如果文件不存在，写入表头）
        if not file_exists(csv_file):
            logging.info(f"文件 {csv_file} 不存在，正在创建并写入表头...")
            with open(csv_file, mode='w', newline='', encoding='utf-8') as file:
                writer = csv.writer(file)
                writer.writerow(['标题'])  # 写入表头
        else:
            logging.info(f"文件 {csv_file} 已存在，将追加数据...")

        while len(titles) < max_titles:
            logging.info(f"正在解析第 {page_count} 页数据...")
            print(f"正在解析第 {page_count} 页数据...")

            results = driver.find_elements(By.CSS_SELECTOR, "div.result.c-container")
            for result in results:
                if len(titles) >= max_titles:
                    break
                try:
                    title_element = result.find_element(By.CSS_SELECTOR, "h3.t")
                    title = title_element.text
                    titles.append(title)
                    logging.info(f"标题: {title}")
                    print(f"标题: {title}")
                except Exception as e:
                    logging.error(f"解析标题时发生异常: {str(e)}")
                    print(f"解析标题时发生异常: {str(e)}")

            # 检查是否已达到目标数量
            if len(titles) >= max_titles:
                logging.info(f"已收集到 {len(titles)} 条标题，停止爬取...")
                print(f"已收集到 {len(titles)} 条标题，停止爬取...")
                break

            # 尝试翻页
            try:
                next_page_button = driver.find_element(By.XPATH, "//a[@class='n' and contains(text(), '下一页')]")
                if next_page_button:
                    logging.info("找到下一页按钮，正在点击...")
                    print("找到下一页按钮，正在点击...")
                    driver.execute_script("arguments[0].scrollIntoView();", next_page_button)  # 滚动到按钮位置
                    next_page_button.click()
                    WebDriverWait(driver, 15).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, "div.result.c-container"))
                    )
                    page_count += 1
                    time.sleep(2)  # 添加适当的延迟
                else:
                    logging.info("没有找到下一页按钮，停止爬取...")
                    print("没有找到下一页按钮，停止爬取...")
                    break
            except Exception as e:
                logging.error(f"找不到下一页按钮或点击失败: {str(e)}")
                print(f"找不到下一页按钮或点击失败: {str(e)}")
                break

            # 每爬取一批数据就写入 CSV 文件
            if len(titles) % batch_size == 0:
                logging.info(f"正在将第 {len(titles) // batch_size} 批数据写入 CSV 文件...")
                print(f"正在将第 {len(titles) // batch_size} 批数据写入 CSV 文件...")
                write_to_csv(titles, csv_file, append=True)

        # 写入剩余的数据
        if len(titles) % batch_size != 0:
            logging.info(f"正在将剩余数据写入 CSV 文件...")
            print(f"正在将剩余数据写入 CSV 文件...")
            write_to_csv(titles, csv_file, append=True)

        logging.info(f"数据解析完成，共收集到 {len(titles)} 条标题")
        print(f"数据解析完成，共收集到 {len(titles)} 条标题")

    except Exception as e:
        logging.error(f"发生异常: {str(e)}")
        print(f"发生异常: {str(e)}")
        if driver is not None:
            logging.info("保存错误截图...")
            print("保存错误截图...")
            driver.save_screenshot("error.png")
    finally:
        if driver is not None:
            logging.info("正在关闭浏览器...")
            print("正在关闭浏览器...")
            driver.quit()

def file_exists(filename):
    """检查文件是否存在"""
    try:
        with open(filename, 'r'):
            return True
    except FileNotFoundError:
        return False

def write_to_csv(titles, filename, append=False):
    """将标题写入 CSV 文件"""
    mode = 'a' if append else 'w'
    with open(filename, mode=mode, newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        if not append and not file_exists(filename):
            writer.writerow(['标题'])  # 写入表头
        for title in titles:
            writer.writerow([title])
    logging.info(f"成功将 {len(titles)} 条标题写入 {filename}")

if __name__ == "__main__":
    logging.info("程序开始运行...")
    print("程序开始运行...")
    main()
    logging.info("程序结束")
    print("程序结束")
            </pre>
        </div>
        <!-- 添加视频 -->
        <h3>数据爬取演示视频</h3>
        <video controls>
            <source src="deepseek.mp4" type="mp4">
        </video>
        <p>以上视频演示了使用 Selenium 爬取百度搜索结果中的新闻标题的过程。</p>
    </div>

    <!-- 词云图制作 -->
    <div class="section">
        <h2>3. 词云图制作</h2>
        <p>
            为了直观展示新闻标题中的关键词，我使用 Python 的 <code>jieba</code> 和 <code>wordcloud</code> 库制作了词云图。以下是制作过程的主要步骤：
        </p>
        <ol>
            <li><strong>数据清洗</strong>：对新闻标题进行分词，去掉标点符号和停用词。</li>
            <li><strong>生成词云</strong>：将分词后的结果拼接成一个字符串，作为词云图的输入。</li>
            <li><strong>保存和展示</strong>：将生成的词云图保存为 PNG 文件（<code>wordcloud.png</code>）。</li>
        </ol>
        <div class="code">
            <pre>
import pandas as pd
from snownlp import SnowNLP
import re
import matplotlib.pyplot as plt
import os

# 读取 CSV 文件
file_path = "D:\\tensorflow\\deepseek_news.csv"  # 文件路径
try:
    df = pd.read_csv(file_path, on_bad_lines='skip', encoding='utf-8')
except pd.errors.ParserError as e:
    print(f"解析 CSV 文件时发生错误: {str(e)}")
    df = pd.read_csv(file_path, on_bad_lines='skip', encoding='utf-8', sep='\t')  # 尝试使用制表符分隔

# 打印文件信息
print("CSV 文件列名:", df.columns)
print(f"总数据量: {len(df)}")
print(df.head())  # 打印前 5 行数据

# 提取标题列（根据实际列名调整）
title_column = None
for col in df.columns:
    if "标题" in col:  # 检查列名是否包含 "标题"
        title_column = col
        break

if title_column:
    titles = df[title_column].tolist()  # 提取标题列
else:
    print("CSV 文件中没有找到包含 '标题' 的列")
    titles = []

# 情感分析函数
def analyze_sentiment(text):
    # 使用 SnowNLP 进行情感分析
    s = SnowNLP(text)
    sentiment_score = s.sentiments  # 情感得分（0-1，越接近1表示越积极）
    return sentiment_score

# 对每条标题进行情感分析
sentiment_results = []
for title in titles:
    try:
        sentiment_score = analyze_sentiment(title)
        sentiment_results.append(sentiment_score)
    except Exception as e:
        print(f"情感分析失败: {title}, 错误: {str(e)}")
        sentiment_results.append(None)  # 如果分析失败，记录为 None

# 将情感分析结果添加到 DataFrame
df["情感得分"] = sentiment_results

# 根据情感得分分类
def classify_sentiment(score):
    if score is None:
        return "未知"
    elif score >= 0.6:
        return "积极"
    elif score <= 0.4:
        return "消极"
    else:
        return "中性"

df["情感分类"] = df["情感得分"].apply(classify_sentiment)

# 保存结果到新的 CSV 文件
output_path = r"D:\tensorflow\deepseek_news_with_sentiment.csv"
df.to_csv(output_path, index=False, encoding='utf-8')
print(f"情感分析结果已保存到 {output_path}")

# 打印情感分析统计结果
print("\n情感分析统计结果:")
print(df["情感分类"].value_counts())

# 生成情感分析结果饼图
sentiment_counts = df["情感分类"].value_counts()

# 设置饼图参数
labels = sentiment_counts.index
sizes = sentiment_counts.values
colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']

# 动态设置 explode 参数
explode = [0.1 if i == 0 else 0 for i in range(len(labels))]

# 打印字体文件路径，确认路径正确
font_path = r"C:\Windows\Fonts\simhei.ttf"  # 确保路径正确
print(f"字体文件路径: {font_path}")

# 检查字体文件是否存在
if not os.path.exists(font_path):
    print(f"字体文件 {font_path} 不存在，请检查路径或安装中文字体。")
else:
    # 设置中文字体
    plt.rcParams['font.sans-serif'] = ['SimHei']  # 设置中文字体
    plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题

    # 绘制饼图
    plt.figure(figsize=(8, 8))
    plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)
    plt.axis('equal')  # 使饼图为正圆
    plt.title("情感分析结果饼图")
    plt.show()

    # 保存饼图为图像文件
    pie_chart_path = r"D:\tensorflow\sentiment_pie_chart.png"
    plt.savefig(pie_chart_path)
    print(f"情感分析结果饼图已保存到 {pie_chart_path}")
            <pre>
from snownlp import SnowNLP

# 情感分析
sentiment_scores = [SnowNLP(title).sentiments for title in titles]

# 分类
sentiment_labels = ["积极" if score >= 0.6 else "消极" if score <= 0.4 else "中性" for score in sentiment_scores]

# 统计结果
sentiment_counts = pd.Series(sentiment_labels).value_counts()

# 生成饼图
plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%')
plt.title("情感分析结果")
plt.savefig("sentiment_pie_chart.png")
            </pre>
        </div>
        <img src="饼图.png" alt="情感分析饼图">
    </div>
</body>
</html>
